{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vN8BzBP9wGoF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCFyciCC4y4w"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B8IK-OcMy17u"
      },
      "outputs": [],
      "source": [
        "dataset = torchvision.datasets.CIFAR10(root='data/',download=True,transform=transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4,padding_mode='reflect'), # augmentation\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(), # CxHxW\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "]))\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='data/',train = False,download=True,transform=transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4,padding_mode='reflect'), # augmentation\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(), # CxHxW\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VRo02Jr4GOw"
      },
      "outputs": [],
      "source": [
        "val_ratio = 0.2\n",
        "train_dataset, val_dataset = random_split(dataset,[int((1-val_ratio)*len(dataset)), int(val_ratio*len(dataset))])\n",
        "batch_size =  32 #higher batch size is better\n",
        "train_dl = DataLoader(train_dataset,batch_size,shuffle=True,pin_memory=True)\n",
        "val_dl = DataLoader(val_dataset,batch_size,shuffle=True,pin_memory=True)\n",
        "test_dl = DataLoader(test_dataset,batch_size,pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q0ATQmNCfJn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "def denormalize(images,means,std_div):\n",
        "  means = torch.tensor(means).reshape(1,3,1,1)\n",
        "  std_div = torch.tensor(std_div).reshape(1,3,1,1)\n",
        "  return images*std_div + means\n",
        "\n",
        "def show_preview(dl,normalized):\n",
        "  for images,labels in dl:\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "    if(normalized):\n",
        "      images = denormalize(images,(0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    ax.imshow(make_grid(images,10).permute(1,2,0)) #H,W,C\n",
        "    break\n",
        "show_preview(train_dl,1)\n",
        "show_preview(train_dl,0)\n",
        "\n",
        "#they appear dark because we had applied normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS2BM6q0R6Gh"
      },
      "outputs": [],
      "source": [
        "def get_default_devices():\n",
        "  return torch.device(\"cuda\").type if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "def to_device(data,device):\n",
        "  if(isinstance(data,(list,tuple))):\n",
        "    return [to_device(x,device) for x in data]\n",
        "  return data.to(device,non_blocking=True)\n",
        "  #non blocking means you dont want to block execution of code when transferring code\n",
        "\n",
        "class DeviceDataLoader():\n",
        "  ''' wrapper around dataloaders to transfer batches to specified devices'''\n",
        "  def __init__(self,dl,device):\n",
        "    self.dl = dl\n",
        "    self.device = device\n",
        "  def __iter__(self):\n",
        "    for b in self.dl:\n",
        "      yield to_device(b,self.device)\n",
        "  def __len__(self):\n",
        "    return len(self.dl)\n",
        "\n",
        "device = get_default_devices()\n",
        "train_dl = DeviceDataLoader(train_dl,device)\n",
        "test_dl = DeviceDataLoader(test_dl,device)\n",
        "val_dl = DeviceDataLoader(val_dl,device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg6sZBaIXoJN"
      },
      "source": [
        "### Network architecture\n",
        "\n",
        "resnets: residual blocks\n",
        "inception\n",
        "mobilenet\n",
        "\n",
        "model = ResnetX(in_channels,num_classes)\n",
        "logits = model(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZYmLJ3BXr8P"
      },
      "outputs": [],
      "source": [
        "from typing import OrderedDict\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def conv_block(in_channels,out_channels,use_pool=False):\n",
        "  layers = [nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1),\n",
        "            nn.BatchNorm2d(out_channels), #skewness doesnt develop in some particular channel\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels,out_channels,kernel_size=3,padding=1),\n",
        "            ]\n",
        "  if(use_pool):\n",
        "    layers.append(nn.MaxPool2d(2))\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "class ResnetX(nn.Module):\n",
        "  def __init__(self,in_channels,num_classes):\n",
        "    super().__init__()\n",
        "    self.conv1 = conv_block(in_channels,64)\n",
        "    self.conv2 = conv_block(64,128,use_pool=True)\n",
        "    # question: how can 1x1 convolution do the same thing ?\n",
        "    self.res1 = nn.Sequential(OrderedDict([(\"conv1 res 1\",conv_block(128,128)),(\"conv2 res 1\",conv_block(128,128))])) # Pass key-value pairs as a single list\n",
        "    self.conv3 = conv_block(128,256)\n",
        "    self.conv4 = conv_block(256,512,use_pool=True)\n",
        "    self.res2 = nn.Sequential(conv_block(512,512),conv_block(512,512))\n",
        "    self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
        "                                    nn.Flatten(),\n",
        "                                    nn.Dropout(0.2), #for good generalization\n",
        "                                    nn.Linear(2048,num_classes))\n",
        "  def forward(self,x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv2(out)\n",
        "    # why not add x ? why add out?\n",
        "    out = self.res1(out) + out\n",
        "    out = self.conv3(out)\n",
        "    out = self.conv4(out)\n",
        "    out = self.res2(out) + out\n",
        "    out = self.classifier(out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EnTaoY1mihd"
      },
      "outputs": [],
      "source": [
        "model = ResnetX(3,10)\n",
        "# model\n",
        "# list(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4-JqAsyn84n"
      },
      "outputs": [],
      "source": [
        "!pip install torchview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6sVmTu3rIVK"
      },
      "outputs": [],
      "source": [
        "from torchview import draw_graph\n",
        "model_graph = draw_graph(model, torch.zeros(1, 3, 32, 32))\n",
        "model_graph.visual_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkIDYgW3tChe"
      },
      "source": [
        "### Training the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEVtBh1otEjo"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dl, val_dl, epochs, max_lr, loss_function, optim):\n",
        "    optimizer = optim(model.parameters(), max_lr)\n",
        "    schedular = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_dl))\n",
        "\n",
        "    results = []\n",
        "    lrs = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "\n",
        "        for images, labels in train_dl:  # for every batch\n",
        "            optimizer.zero_grad()\n",
        "            out = model(images)\n",
        "            loss = loss_function(out, labels)\n",
        "            train_loss.append(loss)\n",
        "            loss.backward()  # delta loss/delta_model_parameters\n",
        "            optimizer.step()\n",
        "            lrs.append(optimizer.param_groups[0]['lr'])\n",
        "            schedular.step()\n",
        "\n",
        "        epoch_train_loss = torch.stack(train_loss).mean()\n",
        "\n",
        "        model.eval()\n",
        "        batch_losses, batch_accs = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_dl:\n",
        "                out = model(images)\n",
        "                loss = loss_function(out, labels)\n",
        "                batch_losses.append(loss)\n",
        "                acc = torch.argmax(out, dim=1) == labels  # BxN\n",
        "                batch_accs.append(acc)\n",
        "\n",
        "        val_loss = torch.stack(batch_losses).mean()\n",
        "        val_acc = torch.stack(batch_accs).mean()\n",
        "\n",
        "        results.append({'avg_train_loss': epoch_train_loss, 'avg_val_loss': val_loss, 'avg_val_acc': val_acc, 'lrs':lrs})\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoiveXVm0gmz"
      },
      "outputs": [],
      "source": [
        "model = to_device(model,device)\n",
        "epochs = 10\n",
        "max_lr = 1e-2\n",
        "loss_func = nn.functional.cross_entropy\n",
        "optim = torch.optim.Adam\n",
        "results = train(model,train_dl,val_dl,epochs,max_lr,loss_func,optim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr2_sWtn05EP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot(results, pairs):\n",
        "    fig, axes = plt.subplots(len(pairs), figsize=(10, 10))\n",
        "\n",
        "    # If there's only one plot, axes is not a list, so convert it to a list\n",
        "    if len(pairs) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i, pair in enumerate(pairs):\n",
        "        for title, graphs in pair.items():\n",
        "            axes[i].set_title(title)\n",
        "            for graph in graphs:\n",
        "                axes[i].plot(results[graph], label=graph)\n",
        "            axes[i].legend()  # Correct way to set legend\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Corrected example input with closing quotes for learning rate\n",
        "plot(results, [{\"Accuracies vs epochs\": [\"avg_val_acc\"],\n",
        "               \"Losses vs epochs\": [\"avg_train_loss\", \"avg_val_loss\"],\n",
        "               \"Learning rate vs Batches\": [\"lrs\"]}])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ6ZztG15LQR"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state.dict(),\"cifar10ResnetX.pth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}